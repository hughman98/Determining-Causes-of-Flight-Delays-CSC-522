{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc28c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "train_set = pd.read_csv(cur_dir + '/../data/train_set_artificial.csv', low_memory=False)\n",
    "test_set = pd.read_csv(cur_dir + '/../data/test_set.csv', low_memory=False)\n",
    "val_set = pd.read_csv(cur_dir + '/../data/validation_set.csv', low_memory=False)\n",
    "\n",
    "#Add validation set to test set, since we wound up using cross validation\n",
    "test_set = pd.concat([test_set, val_set], axis=0)\n",
    "\n",
    "df = pd.concat([train_set, test_set, val_set], axis=0)\n",
    "\n",
    "X_train = train_set.drop(['delay_class'],axis=1)\n",
    "y_train = train_set['delay_class']\n",
    "\n",
    "X_test = test_set.drop(['delay_class'],axis=1)\n",
    "y_test = test_set['delay_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dd1905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Average</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>New Snow</th>\n",
       "      <th>Snow Depth</th>\n",
       "      <th>days_in_365</th>\n",
       "      <th>sched_time_in_min</th>\n",
       "      <th>Precipitation Binary</th>\n",
       "      <th>New Snow Binary</th>\n",
       "      <th>Snow Depth Binary</th>\n",
       "      <th>delay_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MCO</td>\n",
       "      <td>0.170370</td>\n",
       "      <td>0.176219</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.316067</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EV</td>\n",
       "      <td>EWR</td>\n",
       "      <td>MCI</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.206404</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.374012</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B6</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MSY</td>\n",
       "      <td>0.232593</td>\n",
       "      <td>0.224760</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.087796</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B6</td>\n",
       "      <td>EWR</td>\n",
       "      <td>FLL</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>0.200897</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.459695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.579456</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WN</td>\n",
       "      <td>LGA</td>\n",
       "      <td>BNA</td>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.139506</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.250545</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>0.267779</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65464</th>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SJU</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.246187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623626</td>\n",
       "      <td>0.210711</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65465</th>\n",
       "      <td>EV</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.135835</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.344227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164835</td>\n",
       "      <td>0.611062</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65466</th>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>0.441481</td>\n",
       "      <td>0.506833</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.457516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.759438</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65467</th>\n",
       "      <td>DL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PBI</td>\n",
       "      <td>0.198519</td>\n",
       "      <td>0.194779</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.870879</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65468</th>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>0.478519</td>\n",
       "      <td>0.506833</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947802</td>\n",
       "      <td>0.096576</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490308 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      carrier origin dest  air_time  distance   Maximum   Minimum   Average  \\\n",
       "0          DL    JFK  MCO  0.170370  0.176219  0.358025  0.346667  0.350649   \n",
       "1          EV    EWR  MCI  0.229630  0.206404  0.407407  0.333333  0.370130   \n",
       "2          B6    JFK  MSY  0.232593  0.224760  0.308642  0.293333  0.298701   \n",
       "3          B6    EWR  FLL  0.195556  0.200897  0.506173  0.493333  0.500000   \n",
       "4          WN    LGA  BNA  0.130370  0.139506  0.691358  0.773333  0.733766   \n",
       "...       ...    ...  ...       ...       ...       ...       ...       ...   \n",
       "65464      UA    EWR  SJU  0.266667  0.311646  0.740741  0.640000  0.694805   \n",
       "65465      EV    EWR  ATL  0.130370  0.135835  0.259259  0.266667  0.259740   \n",
       "65466      UA    EWR  SFO  0.441481  0.506833  0.814815  0.826667  0.824675   \n",
       "65467      DL    LGA  PBI  0.198519  0.194779  0.407407  0.306667  0.357143   \n",
       "65468      UA    EWR  SFO  0.478519  0.506833  0.098765  0.120000  0.103896   \n",
       "\n",
       "       Departure  Precipitation  New Snow  Snow Depth  days_in_365  \\\n",
       "0       0.418301       0.000000       0.0         0.0     0.917582   \n",
       "1       0.254902       0.000000       0.0         0.0     0.840659   \n",
       "2       0.241830       0.000000       0.0         0.0     0.250000   \n",
       "3       0.459695       0.000000       0.0         0.0     0.274725   \n",
       "4       0.250545       0.004988       0.0         0.0     0.530220   \n",
       "...          ...            ...       ...         ...          ...   \n",
       "65464   0.246187       0.000000       0.0         0.0     0.623626   \n",
       "65465   0.344227       0.000000       0.0         0.0     0.164835   \n",
       "65466   0.457516       0.000000       0.0         0.0     0.494505   \n",
       "65467   0.267974       0.000000       0.0         0.0     0.870879   \n",
       "65468   0.074074       0.000000       0.0         0.0     0.947802   \n",
       "\n",
       "       sched_time_in_min Precipitation Binary New Snow Binary  \\\n",
       "0               0.316067                  yes              no   \n",
       "1               0.374012                  yes              no   \n",
       "2               0.087796                   no              no   \n",
       "3               0.579456                  yes              no   \n",
       "4               0.267779                  yes              no   \n",
       "...                  ...                  ...             ...   \n",
       "65464           0.210711                   no              no   \n",
       "65465           0.611062                  yes             yes   \n",
       "65466           0.759438                  yes              no   \n",
       "65467           0.373134                   no              no   \n",
       "65468           0.096576                   no              no   \n",
       "\n",
       "      Snow Depth Binary delay_class  \n",
       "0                    no          no  \n",
       "1                    no          no  \n",
       "2                    no          no  \n",
       "3                    no         yes  \n",
       "4                    no          no  \n",
       "...                 ...         ...  \n",
       "65464                no         yes  \n",
       "65465                no          no  \n",
       "65466                no         yes  \n",
       "65467                no          no  \n",
       "65468                no          no  \n",
       "\n",
       "[490308 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc47d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Transform categorical features into binary features\n",
    "categorical_columns = list(X_train.select_dtypes(include=['object']).columns)\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Use df to fit the encoder to prevent scenarios that the binary features in train and test sets are different, \n",
    "# For example, test set has dest_LAX, but train set does not have dest_LAX\n",
    "encoder.fit(df[categorical_columns])\n",
    "\n",
    "X_train_category = encoder.transform(X_train[categorical_columns])\n",
    "X_test_category = encoder.transform(X_test[categorical_columns])\n",
    "\n",
    "# Get numerical features\n",
    "numerical_columns = list(X_train.select_dtypes(include=['float64']).columns)\n",
    "\n",
    "# Combine the numerical and categorical features\n",
    "X_train_df_category = pd.DataFrame(X_train_category.toarray())\n",
    "X_train_df_category.columns = encoder.get_feature_names_out()\n",
    "X_train_df_numerical = pd.DataFrame(X_train[numerical_columns]).reset_index(drop=True)\n",
    "X_train_encoded = pd.concat([X_train_df_numerical, X_train_df_category], axis=1)\n",
    "\n",
    "\n",
    "X_test_df_category = pd.DataFrame(X_test_category.toarray())\n",
    "X_test_df_category.columns = encoder.get_feature_names_out()\n",
    "X_test_df_numerical = pd.DataFrame(X_test[numerical_columns]).reset_index(drop=True)\n",
    "X_test_encoded = pd.concat([X_test_df_numerical, X_test_df_category], axis=1)\n",
    "\n",
    "# Drop encoded columns that have very few positive values, in order to reduce our dimensionality.\n",
    "# These columns were identified in \"DropOneHotEncodingColumn.ipynb\"\n",
    "columns_to_drop = ['dest_CHO', 'dest_BUF', 'dest_CAE', 'dest_CHS', 'dest_BUR', 'dest_BQN', 'dest_BGR', 'dest_SNA', 'dest_IND', 'dest_ABQ', 'dest_BWI', 'dest_OAK', 'dest_SAN', 'dest_SDF', 'dest_HNL', 'dest_GSP', 'dest_TUL', 'dest_TYS', 'dest_RSW', 'New Snow Binary_no','dest_SBN', 'dest_OMA', 'dest_GRR', 'dest_BDL', 'dest_MKE', 'dest_PWM', 'dest_DSM', 'dest_JAX', 'dest_HDN','dest_STL','Precipitation Binary_no','dest_EYW','dest_EGE','dest_PVD','dest_PSE','dest_PDX','dest_MTJ','dest_MEM','dest_JAC','dest_SAV','dest_SLC','dest_CAK','dest_RIC','dest_MVY','dest_LEX','dest_DAY','dest_PIT','dest_CRW','dest_BZN','dest_ORF','dest_BTV','dest_XNA','dest_IAD','dest_GSO','dest_MHT','dest_SEA','dest_SRQ','dest_PSP','dest_ANC','dest_CVG','dest_STT','dest_MYR','dest_SJC','dest_MDW','dest_AUS','dest_ACK','dest_CMH','dest_PHL','dest_MSN','dest_SMF','dest_CLE','dest_PHX','dest_AVL','dest_ALB','dest_ILM','dest_ROC','Snow Depth Binary_no','dest_MCI','dest_HOU','dest_LAS','dest_OKC','dest_SAT','dest_TVC','dest_SYR','dest_BHM','dest_LGB','dest_MSY']\n",
    "\n",
    "X_train_encoded.drop(columns_to_drop, axis=1, inplace=True)\n",
    "X_test_encoded.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a5a0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Average</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>New Snow</th>\n",
       "      <th>Snow Depth</th>\n",
       "      <th>days_in_365</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_MSP</th>\n",
       "      <th>dest_ORD</th>\n",
       "      <th>dest_PBI</th>\n",
       "      <th>dest_RDU</th>\n",
       "      <th>dest_SFO</th>\n",
       "      <th>dest_SJU</th>\n",
       "      <th>dest_TPA</th>\n",
       "      <th>Precipitation Binary_yes</th>\n",
       "      <th>New Snow Binary_yes</th>\n",
       "      <th>Snow Depth Binary_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.170370</td>\n",
       "      <td>0.176219</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.206404</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232593</td>\n",
       "      <td>0.224760</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195556</td>\n",
       "      <td>0.200897</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.459695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.139506</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.250545</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293895</th>\n",
       "      <td>0.432344</td>\n",
       "      <td>0.483009</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.405229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293896</th>\n",
       "      <td>0.119368</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293897</th>\n",
       "      <td>0.182222</td>\n",
       "      <td>0.207220</td>\n",
       "      <td>0.595520</td>\n",
       "      <td>0.589003</td>\n",
       "      <td>0.593587</td>\n",
       "      <td>0.350269</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293898</th>\n",
       "      <td>0.048651</td>\n",
       "      <td>0.045074</td>\n",
       "      <td>0.738151</td>\n",
       "      <td>0.736785</td>\n",
       "      <td>0.740578</td>\n",
       "      <td>0.395707</td>\n",
       "      <td>0.018992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293899</th>\n",
       "      <td>0.152221</td>\n",
       "      <td>0.143801</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.169576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293900 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        air_time  distance   Maximum   Minimum   Average  Departure  \\\n",
       "0       0.170370  0.176219  0.358025  0.346667  0.350649   0.418301   \n",
       "1       0.229630  0.206404  0.407407  0.333333  0.370130   0.254902   \n",
       "2       0.232593  0.224760  0.308642  0.293333  0.298701   0.241830   \n",
       "3       0.195556  0.200897  0.506173  0.493333  0.500000   0.459695   \n",
       "4       0.130370  0.139506  0.691358  0.773333  0.733766   0.250545   \n",
       "...          ...       ...       ...       ...       ...        ...   \n",
       "293895  0.432344  0.483009  0.716049  0.666667  0.694805   0.405229   \n",
       "293896  0.119368  0.122401  0.740741  0.680000  0.714286   0.601307   \n",
       "293897  0.182222  0.207220  0.595520  0.589003  0.593587   0.350269   \n",
       "293898  0.048651  0.045074  0.738151  0.736785  0.740578   0.395707   \n",
       "293899  0.152221  0.143801  0.481481  0.426667  0.454545   0.612200   \n",
       "\n",
       "        Precipitation  New Snow  Snow Depth  days_in_365  ...  dest_MSP  \\\n",
       "0            0.000000       0.0         0.0     0.917582  ...       0.0   \n",
       "1            0.000000       0.0         0.0     0.840659  ...       0.0   \n",
       "2            0.000000       0.0         0.0     0.250000  ...       0.0   \n",
       "3            0.000000       0.0         0.0     0.274725  ...       0.0   \n",
       "4            0.004988       0.0         0.0     0.530220  ...       0.0   \n",
       "...               ...       ...         ...          ...  ...       ...   \n",
       "293895       0.000000       0.0         0.0     0.445055  ...       0.0   \n",
       "293896       0.000000       0.0         0.0     0.758242  ...       0.0   \n",
       "293897       0.002057       0.0         0.0     0.372975  ...       0.0   \n",
       "293898       0.018992       0.0         0.0     0.480462  ...       0.0   \n",
       "293899       0.169576       0.0         0.0     0.192308  ...       0.0   \n",
       "\n",
       "        dest_ORD  dest_PBI  dest_RDU  dest_SFO  dest_SJU  dest_TPA  \\\n",
       "0            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "293895       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "293896       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "293897       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "293898       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "293899       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "        Precipitation Binary_yes  New Snow Binary_yes  Snow Depth Binary_yes  \n",
       "0                            1.0                  0.0                    0.0  \n",
       "1                            1.0                  0.0                    0.0  \n",
       "2                            0.0                  0.0                    0.0  \n",
       "3                            1.0                  0.0                    0.0  \n",
       "4                            1.0                  0.0                    0.0  \n",
       "...                          ...                  ...                    ...  \n",
       "293895                       0.0                  0.0                    0.0  \n",
       "293896                       0.0                  0.0                    0.0  \n",
       "293897                       1.0                  0.0                    0.0  \n",
       "293898                       1.0                  0.0                    0.0  \n",
       "293899                       1.0                  0.0                    0.0  \n",
       "\n",
       "[293900 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa6850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Average</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>New Snow</th>\n",
       "      <th>Snow Depth</th>\n",
       "      <th>days_in_365</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_MSP</th>\n",
       "      <th>dest_ORD</th>\n",
       "      <th>dest_PBI</th>\n",
       "      <th>dest_RDU</th>\n",
       "      <th>dest_SFO</th>\n",
       "      <th>dest_SJU</th>\n",
       "      <th>dest_TPA</th>\n",
       "      <th>Precipitation Binary_yes</th>\n",
       "      <th>New Snow Binary_yes</th>\n",
       "      <th>Snow Depth Binary_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.305185</td>\n",
       "      <td>0.267387</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.112219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.488476</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.501089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.405926</td>\n",
       "      <td>0.437895</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183704</td>\n",
       "      <td>0.139099</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.385621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171852</td>\n",
       "      <td>0.133184</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.305195</td>\n",
       "      <td>0.405229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130934</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.246187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130935</th>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.135835</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.344227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130936</th>\n",
       "      <td>0.441481</td>\n",
       "      <td>0.506833</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.457516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130937</th>\n",
       "      <td>0.198519</td>\n",
       "      <td>0.194779</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.870879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130938</th>\n",
       "      <td>0.478519</td>\n",
       "      <td>0.506833</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130939 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        air_time  distance   Maximum   Minimum   Average  Departure  \\\n",
       "0       0.305185  0.267387  0.444444  0.253333  0.350649   0.627451   \n",
       "1       0.407407  0.488476  0.827160  0.840000  0.837662   0.501089   \n",
       "2       0.405926  0.437895  0.296296  0.253333  0.272727   0.294118   \n",
       "3       0.183704  0.139099  0.790123  0.813333  0.805195   0.385621   \n",
       "4       0.171852  0.133184  0.345679  0.266667  0.305195   0.405229   \n",
       "...          ...       ...       ...       ...       ...        ...   \n",
       "130934  0.266667  0.311646  0.740741  0.640000  0.694805   0.246187   \n",
       "130935  0.130370  0.135835  0.259259  0.266667  0.259740   0.344227   \n",
       "130936  0.441481  0.506833  0.814815  0.826667  0.824675   0.457516   \n",
       "130937  0.198519  0.194779  0.407407  0.306667  0.357143   0.267974   \n",
       "130938  0.478519  0.506833  0.098765  0.120000  0.103896   0.074074   \n",
       "\n",
       "        Precipitation  New Snow  Snow Depth  days_in_365  ...  dest_MSP  \\\n",
       "0            0.112219       0.0         0.0     0.082418  ...       0.0   \n",
       "1            0.000000       0.0         0.0     0.516484  ...       0.0   \n",
       "2            0.000000       0.0         0.0     0.197802  ...       0.0   \n",
       "3            0.000000       0.0         0.0     0.607143  ...       0.0   \n",
       "4            0.000000       0.0         0.1     0.967033  ...       0.0   \n",
       "...               ...       ...         ...          ...  ...       ...   \n",
       "130934       0.000000       0.0         0.0     0.623626  ...       0.0   \n",
       "130935       0.000000       0.0         0.0     0.164835  ...       0.0   \n",
       "130936       0.000000       0.0         0.0     0.494505  ...       0.0   \n",
       "130937       0.000000       0.0         0.0     0.870879  ...       0.0   \n",
       "130938       0.000000       0.0         0.0     0.947802  ...       0.0   \n",
       "\n",
       "        dest_ORD  dest_PBI  dest_RDU  dest_SFO  dest_SJU  dest_TPA  \\\n",
       "0            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4            1.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "130934       0.0       0.0       0.0       0.0       1.0       0.0   \n",
       "130935       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "130936       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "130937       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "130938       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "\n",
       "        Precipitation Binary_yes  New Snow Binary_yes  Snow Depth Binary_yes  \n",
       "0                            1.0                  1.0                    0.0  \n",
       "1                            0.0                  0.0                    0.0  \n",
       "2                            1.0                  1.0                    0.0  \n",
       "3                            0.0                  0.0                    0.0  \n",
       "4                            0.0                  0.0                    1.0  \n",
       "...                          ...                  ...                    ...  \n",
       "130934                       0.0                  0.0                    0.0  \n",
       "130935                       1.0                  1.0                    0.0  \n",
       "130936                       1.0                  0.0                    0.0  \n",
       "130937                       0.0                  0.0                    0.0  \n",
       "130938                       0.0                  0.0                    0.0  \n",
       "\n",
       "[130939 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ba4714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Fitting 4 folds for each of 60 candidates, totalling 240 fits\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   9.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   7.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   6.8s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   9.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   7.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   8.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   9.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   7.1s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   5.3s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   6.0s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   6.5s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  15.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  10.6s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  10.6s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=  10.4s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.3s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.3s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   2.8s\n",
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=   7.2s\n",
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=   6.2s\n",
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=   6.4s\n",
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.67452e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.21252e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.16947e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.07913e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=  10.2s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   7.6s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   8.0s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   8.7s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   5.3s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   4.2s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   4.6s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   4.7s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  15.8s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  12.3s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  11.8s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   8.2s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   6.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   7.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=  16.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  20.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.3s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.3s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   2.6s\n",
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.67452e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.21252e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.16947e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.07913e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   4.2s\n",
      "[CV] END .....................C=15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................C=15, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=15, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=15, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .................C=15, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...........C=15, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=15, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=15, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=15, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .......................C=15, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=15, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=15, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=15, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=15, penalty=l1, solver=saga; total time=  23.8s\n",
      "[CV] END ......................C=15, penalty=l1, solver=saga; total time=  17.7s\n",
      "[CV] END ......................C=15, penalty=l1, solver=saga; total time=  16.9s\n",
      "[CV] END ......................C=15, penalty=l1, solver=saga; total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=l2, solver=lbfgs; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=l2, solver=lbfgs; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=l2, solver=lbfgs; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END .................C=15, penalty=l2, solver=newton-cg; total time=   6.7s\n",
      "[CV] END .................C=15, penalty=l2, solver=newton-cg; total time=   9.6s\n",
      "[CV] END .................C=15, penalty=l2, solver=newton-cg; total time=   7.0s\n",
      "[CV] END .................C=15, penalty=l2, solver=newton-cg; total time=  10.6s\n",
      "[CV] END ...........C=15, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ...........C=15, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ...........C=15, penalty=l2, solver=newton-cholesky; total time=   0.8s\n",
      "[CV] END ...........C=15, penalty=l2, solver=newton-cholesky; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=15, penalty=l2, solver=sag; total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=15, penalty=l2, solver=sag; total time=  16.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=15, penalty=l2, solver=sag; total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=15, penalty=l2, solver=sag; total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=15, penalty=l2, solver=saga; total time=  20.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=15, penalty=l2, solver=saga; total time=  21.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=15, penalty=l2, solver=saga; total time=  18.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=15, penalty=l2, solver=saga; total time=  17.5s\n",
      "[CV] END .............C=15, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=15, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=15, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=15, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=15, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=15, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=15, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=15, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ...C=15, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=15, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=15, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=15, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...............C=15, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=15, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=15, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=15, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=15, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ..............C=15, penalty=elasticnet, solver=saga; total time=   0.3s\n",
      "[CV] END ..............C=15, penalty=elasticnet, solver=saga; total time=   0.3s\n",
      "[CV] END ..............C=15, penalty=elasticnet, solver=saga; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=15, penalty=None, solver=lbfgs; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=15, penalty=None, solver=lbfgs; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=15, penalty=None, solver=lbfgs; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=15, penalty=None, solver=lbfgs; total time=   2.8s\n",
      "[CV] END ...............C=15, penalty=None, solver=newton-cg; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=15, penalty=None, solver=newton-cg; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=15, penalty=None, solver=newton-cg; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=15, penalty=None, solver=newton-cg; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.67452e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=15, penalty=None, solver=newton-cholesky; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=2.21252e-17): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=15, penalty=None, solver=newton-cholesky; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.16947e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=15, penalty=None, solver=newton-cholesky; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=6.07913e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=15, penalty=None, solver=newton-cholesky; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=None, solver=sag; total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=None, solver=sag; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=None, solver=sag; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=15, penalty=None, solver=sag; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=15, penalty=None, solver=saga; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=15, penalty=None, solver=saga; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=15, penalty=None, solver=saga; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=15, penalty=None, solver=saga; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "108 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.65930248 0.6593229\n",
      " 0.65929568 0.65929228 0.65930589 0.65929568        nan        nan\n",
      "        nan        nan        nan 0.65927867 0.65931609 0.65938414\n",
      " 0.6593195  0.6593195         nan        nan        nan        nan\n",
      " 0.65931609 0.65930929 0.65930929 0.65931269 0.65930929 0.65930929\n",
      "        nan        nan        nan        nan        nan 0.65927867\n",
      " 0.65931609 0.65938414 0.65930929 0.65931269        nan        nan\n",
      "        nan        nan 0.6593195  0.65937053 0.65930589 0.65930589\n",
      " 0.65930589 0.65930589        nan        nan        nan        nan\n",
      "        nan 0.65927867 0.65931609 0.65938414 0.65930589 0.65929908]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.45564e-18): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search complete!\n",
      "Best Hyperparameters: {'C': 1, 'penalty': None, 'solver': 'newton-cholesky'}\n",
      "Accuracy: 65.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1','l2','elasticnet',None],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'C': [1, 10, 15]\n",
    "}\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "grid_search = GridSearchCV(classifier, param_grid=param_grid, cv=4, verbose=2)\n",
    "grid_search.fit(X_train_encoded, y_train)\n",
    "print(\"Grid Search complete!\")\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "accuracy = grid_search.score(X_test_encoded, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "classifier = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ce7233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64388 33707]\n",
      " [11446 21398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.85      0.66      0.74     98095\n",
      "         yes       0.39      0.65      0.49     32844\n",
      "\n",
      "    accuracy                           0.66    130939\n",
      "   macro avg       0.62      0.65      0.61    130939\n",
      "weighted avg       0.73      0.66      0.68    130939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = classifier.predict(X_test_encoded)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
